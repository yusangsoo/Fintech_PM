{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0414b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59d434",
   "metadata": {},
   "source": [
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash\n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline -> 종속변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869a00dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852a0291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a684330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb55b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>0.246114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000   \n",
       "mean      7.215307     0.339666     0.318633     5.443235     0.056034   \n",
       "std       1.296434     0.164636     0.145318     4.757804     0.035034   \n",
       "min       3.800000     0.080000     0.000000     0.600000     0.009000   \n",
       "25%       6.400000     0.230000     0.250000     1.800000     0.038000   \n",
       "50%       7.000000     0.290000     0.310000     3.000000     0.047000   \n",
       "75%       7.700000     0.400000     0.390000     8.100000     0.065000   \n",
       "max      15.900000     1.580000     1.660000    65.800000     0.611000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000   \n",
       "mean     30.525319   115.744574     0.994697     3.218501     0.531268   \n",
       "std      17.749400    56.521855     0.002999     0.160787     0.148806   \n",
       "min       1.000000     6.000000     0.987110     2.720000     0.220000   \n",
       "25%      17.000000    77.000000     0.992340     3.110000     0.430000   \n",
       "50%      29.000000   118.000000     0.994890     3.210000     0.510000   \n",
       "75%      41.000000   156.000000     0.996990     3.320000     0.600000   \n",
       "max     289.000000   440.000000     1.038980     4.010000     2.000000   \n",
       "\n",
       "                10           11           12  \n",
       "count  6497.000000  6497.000000  6497.000000  \n",
       "mean     10.491801     5.818378     0.246114  \n",
       "std       1.192712     0.873255     0.430779  \n",
       "min       8.000000     3.000000     0.000000  \n",
       "25%       9.500000     5.000000     0.000000  \n",
       "50%      10.300000     6.000000     0.000000  \n",
       "75%      11.300000     6.000000     0.000000  \n",
       "max      14.900000     9.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6624a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis = 1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197d16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4bc900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231,  2.41176471, -2.21428571, ...,  0.29411765,\n",
       "        -0.5       , -1.        ],\n",
       "       [ 0.61538462,  3.47058824, -2.21428571, ...,  1.        ,\n",
       "        -0.27777778, -1.        ],\n",
       "       [ 0.61538462,  2.76470588, -1.92857143, ...,  0.82352941,\n",
       "        -0.27777778, -1.        ],\n",
       "       ...,\n",
       "       [-0.38461538, -0.29411765, -0.85714286, ..., -0.29411765,\n",
       "        -0.5       ,  0.        ],\n",
       "       [-1.15384615,  0.        , -0.07142857, ..., -0.76470588,\n",
       "         1.38888889,  1.        ],\n",
       "       [-0.76923077, -0.47058824,  0.5       , ..., -1.11764706,\n",
       "         0.83333333,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c352859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f493405",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size = 0.4, stratify = y, random_state = 7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = 0.5, stratify = y_valid, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0ab43",
   "metadata": {},
   "source": [
    "## tensorflow 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44430068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d216ae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:26:47.063765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:26:47.065823: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-10 10:26:47.146786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:26:47.146848: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-10 10:26:47.146884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = X_train.shape[1], activation = 'relu')) # 입력층, input_dim은 독립변수의 컬럼 수\n",
    "model.add(Dense(64, activation = 'relu')) # 은닉층 1\n",
    "model.add(Dense(32, activation = 'relu')) # 은닉층 2\n",
    "model.add(Dense(16, activation = 'relu')) # 은닉층 3\n",
    "model.add(Dense(1, activation = 'sigmoid')) # 출력층, 이진분류이기 때문에 activation을 sigmoid로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0355c3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,153\n",
      "Trainable params: 5,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# binary_crossentropy로 기준을 정해라 = 이진분류일 경우\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dbde16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:27:30.450501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:27:30.526429: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:27:30.526487: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 43ms/step - loss: 0.6608 - accuracy: 0.7532 - val_loss: 0.6213 - val_accuracy: 0.9038\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5942 - accuracy: 0.9238 - val_loss: 0.5462 - val_accuracy: 0.9377\n",
      "Epoch 3/300\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5453 - accuracy: 0.9650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:27:30.901818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:27:30.929235: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:27:30.929306: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5098 - accuracy: 0.9564 - val_loss: 0.4527 - val_accuracy: 0.9523\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4093 - accuracy: 0.9669 - val_loss: 0.3490 - val_accuracy: 0.9600\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3022 - accuracy: 0.9756 - val_loss: 0.2470 - val_accuracy: 0.9700\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2020 - accuracy: 0.9828 - val_loss: 0.1625 - val_accuracy: 0.9777\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1260 - accuracy: 0.9864 - val_loss: 0.1073 - val_accuracy: 0.9800\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0808 - accuracy: 0.9869 - val_loss: 0.0792 - val_accuracy: 0.9815\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0583 - accuracy: 0.9890 - val_loss: 0.0662 - val_accuracy: 0.9831\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 0.0593 - val_accuracy: 0.9885\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0416 - accuracy: 0.9908 - val_loss: 0.0556 - val_accuracy: 0.9885\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0373 - accuracy: 0.9920 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0347 - accuracy: 0.9926 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9938 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9949 - val_loss: 0.0473 - val_accuracy: 0.9900\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0290 - accuracy: 0.9946 - val_loss: 0.0465 - val_accuracy: 0.9900\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0281 - accuracy: 0.9951 - val_loss: 0.0455 - val_accuracy: 0.9900\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0273 - accuracy: 0.9959 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.9959 - val_loss: 0.0440 - val_accuracy: 0.9900\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.9964 - val_loss: 0.0422 - val_accuracy: 0.9915\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0233 - accuracy: 0.9964 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.0403 - val_accuracy: 0.9915\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9967 - val_loss: 0.0397 - val_accuracy: 0.9915\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0219 - accuracy: 0.9972 - val_loss: 0.0393 - val_accuracy: 0.9915\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0216 - accuracy: 0.9972 - val_loss: 0.0386 - val_accuracy: 0.9915\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0210 - accuracy: 0.9972 - val_loss: 0.0384 - val_accuracy: 0.9915\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.0383 - val_accuracy: 0.9923\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 0.9974 - val_loss: 0.0368 - val_accuracy: 0.9915\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0202 - accuracy: 0.9972 - val_loss: 0.0365 - val_accuracy: 0.9915\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9974 - val_loss: 0.0366 - val_accuracy: 0.9938\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0195 - accuracy: 0.9974 - val_loss: 0.0357 - val_accuracy: 0.9923\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9974 - val_loss: 0.0349 - val_accuracy: 0.9915\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.0350 - val_accuracy: 0.9938\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 0.0352 - val_accuracy: 0.9946\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.0345 - val_accuracy: 0.9946\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 0.9974 - val_loss: 0.0337 - val_accuracy: 0.9938\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.0340 - val_accuracy: 0.9946\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9974 - val_loss: 0.0342 - val_accuracy: 0.9938\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: 0.0340 - val_accuracy: 0.9938\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0175 - accuracy: 0.9974 - val_loss: 0.0331 - val_accuracy: 0.9938\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.0321 - val_accuracy: 0.9946\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.0327 - val_accuracy: 0.9938\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.0325 - val_accuracy: 0.9938\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.0315 - val_accuracy: 0.9946\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 0.0313 - val_accuracy: 0.9938\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9974 - val_loss: 0.0313 - val_accuracy: 0.9938\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.0314 - val_accuracy: 0.9938\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.0312 - val_accuracy: 0.9938\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.0316 - val_accuracy: 0.9938\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.0303 - val_accuracy: 0.9938\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.0297 - val_accuracy: 0.9938\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.0312 - val_accuracy: 0.9938\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 0.0297 - val_accuracy: 0.9938\n",
      "Epoch 59/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.0290 - val_accuracy: 0.9938\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0295 - val_accuracy: 0.9938\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.0299 - val_accuracy: 0.9938\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0290 - val_accuracy: 0.9938\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.0285 - val_accuracy: 0.9938\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0286 - val_accuracy: 0.9931\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.0300 - val_accuracy: 0.9938\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 0.0290 - val_accuracy: 0.9938\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0288 - val_accuracy: 0.9938\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.0286 - val_accuracy: 0.9938\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.0293 - val_accuracy: 0.9931\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.0282 - val_accuracy: 0.9938\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0279 - val_accuracy: 0.9938\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0309 - val_accuracy: 0.9931\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0290 - val_accuracy: 0.9931\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0289 - val_accuracy: 0.9938\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.0298 - val_accuracy: 0.9931\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.0293 - val_accuracy: 0.9931\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0289 - val_accuracy: 0.9931\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0299 - val_accuracy: 0.9923\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9923\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.0298 - val_accuracy: 0.9923\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.0295 - val_accuracy: 0.9931\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0302 - val_accuracy: 0.9931\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9923\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0294 - val_accuracy: 0.9931\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0297 - val_accuracy: 0.9931\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0301 - val_accuracy: 0.9931\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0303 - val_accuracy: 0.9931\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0299 - val_accuracy: 0.9931\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0295 - val_accuracy: 0.9931\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0306 - val_accuracy: 0.9931\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0315 - val_accuracy: 0.9915\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0302 - val_accuracy: 0.9931\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9931\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9931\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0306 - val_accuracy: 0.9931\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0300 - val_accuracy: 0.9931\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0306 - val_accuracy: 0.9923\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9931\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0316 - val_accuracy: 0.9923\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0319 - val_accuracy: 0.9923\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.9923\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9923\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0303 - val_accuracy: 0.9923\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0304 - val_accuracy: 0.9923\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9923\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9923\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0310 - val_accuracy: 0.9923\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9923\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0310 - val_accuracy: 0.9923\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0311 - val_accuracy: 0.9915\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9923\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 117/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9923\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9915\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0304 - val_accuracy: 0.9915\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9915\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0303 - val_accuracy: 0.9915\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0297 - val_accuracy: 0.9923\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0296 - val_accuracy: 0.9923\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0297 - val_accuracy: 0.9923\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0292 - val_accuracy: 0.9931\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0294 - val_accuracy: 0.9931\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0291 - val_accuracy: 0.9931\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0291 - val_accuracy: 0.9931\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0292 - val_accuracy: 0.9923\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0290 - val_accuracy: 0.9931\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0289 - val_accuracy: 0.9931\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0284 - val_accuracy: 0.9931\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0278 - val_accuracy: 0.9931\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0284 - val_accuracy: 0.9923\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0284 - val_accuracy: 0.9923\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9931\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9923\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 0.9923\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0283 - val_accuracy: 0.9923\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0286 - val_accuracy: 0.9923\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0289 - val_accuracy: 0.9915\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0294 - val_accuracy: 0.9915\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.0298 - val_accuracy: 0.9908\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0300 - val_accuracy: 0.9908\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0313 - val_accuracy: 0.9908\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0318 - val_accuracy: 0.9908\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 9.6041e-04 - accuracy: 0.9997 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 9.3829e-04 - accuracy: 0.9997 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 8.7258e-04 - accuracy: 0.9997 - val_loss: 0.0321 - val_accuracy: 0.9908\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 8.3966e-04 - accuracy: 0.9997 - val_loss: 0.0321 - val_accuracy: 0.9908\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 8.0248e-04 - accuracy: 0.9997 - val_loss: 0.0317 - val_accuracy: 0.9908\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 7.8804e-04 - accuracy: 0.9997 - val_loss: 0.0326 - val_accuracy: 0.9908\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 7.6287e-04 - accuracy: 0.9997 - val_loss: 0.0332 - val_accuracy: 0.9908\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 7.4877e-04 - accuracy: 0.9997 - val_loss: 0.0337 - val_accuracy: 0.9908\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 7.5235e-04 - accuracy: 0.9997 - val_loss: 0.0336 - val_accuracy: 0.9908\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 7.6142e-04 - accuracy: 0.9997 - val_loss: 0.0334 - val_accuracy: 0.9908\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 7.1277e-04 - accuracy: 0.9997 - val_loss: 0.0340 - val_accuracy: 0.9908\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 6.9523e-04 - accuracy: 0.9997 - val_loss: 0.0341 - val_accuracy: 0.9908\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.9133e-04 - accuracy: 0.9997 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.7087e-04 - accuracy: 0.9997 - val_loss: 0.0344 - val_accuracy: 0.9908\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.0611e-04 - accuracy: 0.9997 - val_loss: 0.0344 - val_accuracy: 0.9908\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.9020e-04 - accuracy: 0.9997 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 7.2071e-04 - accuracy: 0.9997 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.8792e-04 - accuracy: 0.9997 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 6.7783e-04 - accuracy: 0.9997 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.4724e-04 - accuracy: 0.9997 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.3662e-04 - accuracy: 0.9997 - val_loss: 0.0339 - val_accuracy: 0.9908\n",
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 6.4167e-04 - accuracy: 0.9997 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 176/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step - loss: 6.3541e-04 - accuracy: 0.9997 - val_loss: 0.0356 - val_accuracy: 0.9908\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2274e-04 - accuracy: 0.9997 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2928e-04 - accuracy: 0.9997 - val_loss: 0.0355 - val_accuracy: 0.9908\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.1224e-04 - accuracy: 0.9997 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2515e-04 - accuracy: 0.9997 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2445e-04 - accuracy: 0.9997 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2850e-04 - accuracy: 0.9997 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.6388e-04 - accuracy: 0.9995 - val_loss: 0.0365 - val_accuracy: 0.9915\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 6.9590e-04 - accuracy: 0.9992 - val_loss: 0.0363 - val_accuracy: 0.9908\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.1133e-04 - accuracy: 0.9997 - val_loss: 0.0363 - val_accuracy: 0.9908\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5.9207e-04 - accuracy: 0.9997 - val_loss: 0.0364 - val_accuracy: 0.9908\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.1773e-04 - accuracy: 0.9997 - val_loss: 0.0364 - val_accuracy: 0.9908\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.8811e-04 - accuracy: 0.9997 - val_loss: 0.0366 - val_accuracy: 0.9908\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.9046e-04 - accuracy: 0.9997 - val_loss: 0.0366 - val_accuracy: 0.9908\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.0535e-04 - accuracy: 0.9997 - val_loss: 0.0365 - val_accuracy: 0.9908\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.6614e-04 - accuracy: 0.9997 - val_loss: 0.0366 - val_accuracy: 0.9908\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.1719e-04 - accuracy: 0.9997 - val_loss: 0.0369 - val_accuracy: 0.9908\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.8754e-04 - accuracy: 0.9997 - val_loss: 0.0372 - val_accuracy: 0.9915\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.8877e-04 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 0.9908\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.6824e-04 - accuracy: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9908\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.6701e-04 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9908\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.0449e-04 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.8727e-04 - accuracy: 0.9992 - val_loss: 0.0373 - val_accuracy: 0.9915\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.4057e-04 - accuracy: 0.9995 - val_loss: 0.0363 - val_accuracy: 0.9908\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.7096e-04 - accuracy: 0.9997 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.0919e-04 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 0.9908\n",
      "Epoch 202/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.9314e-04 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 203/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.6366e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9915\n",
      "Epoch 204/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5.7244e-04 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 0.9915\n",
      "Epoch 205/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.0783e-04 - accuracy: 0.9997 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 206/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.5758e-04 - accuracy: 0.9997 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 207/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6001e-04 - accuracy: 0.9997 - val_loss: 0.0365 - val_accuracy: 0.9908\n",
      "Epoch 208/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.6705e-04 - accuracy: 0.9997 - val_loss: 0.0369 - val_accuracy: 0.9915\n",
      "Epoch 209/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.9561e-04 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9908\n",
      "Epoch 210/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 5.5109e-04 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9908\n",
      "Epoch 211/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 6.0043e-04 - accuracy: 0.9997 - val_loss: 0.0369 - val_accuracy: 0.9915\n",
      "Epoch 212/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.5327e-04 - accuracy: 0.9997 - val_loss: 0.0369 - val_accuracy: 0.9915\n",
      "Epoch 213/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.5038e-04 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9908\n",
      "Epoch 214/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5.6391e-04 - accuracy: 0.9997 - val_loss: 0.0368 - val_accuracy: 0.9908\n",
      "Epoch 215/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.5808e-04 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 0.9908\n",
      "Epoch 216/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4438e-04 - accuracy: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9908\n",
      "Epoch 217/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3849e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 218/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.4442e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9915\n",
      "Epoch 219/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.5299e-04 - accuracy: 0.9997 - val_loss: 0.0375 - val_accuracy: 0.9915\n",
      "Epoch 220/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.6712e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 221/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.5281e-04 - accuracy: 0.9997 - val_loss: 0.0375 - val_accuracy: 0.9915\n",
      "Epoch 222/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.5152e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 223/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4307e-04 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 224/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5.3075e-04 - accuracy: 0.9997 - val_loss: 0.0380 - val_accuracy: 0.9908\n",
      "Epoch 225/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.8216e-04 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9908\n",
      "Epoch 226/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 6.0789e-04 - accuracy: 0.9997 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
      "Epoch 227/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4665e-04 - accuracy: 0.9997 - val_loss: 0.0380 - val_accuracy: 0.9915\n",
      "Epoch 228/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3390e-04 - accuracy: 0.9997 - val_loss: 0.0380 - val_accuracy: 0.9908\n",
      "Epoch 229/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6410e-04 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9908\n",
      "Epoch 230/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3626e-04 - accuracy: 0.9997 - val_loss: 0.0381 - val_accuracy: 0.9908\n",
      "Epoch 231/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3743e-04 - accuracy: 0.9997 - val_loss: 0.0382 - val_accuracy: 0.9908\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3522e-04 - accuracy: 0.9997 - val_loss: 0.0386 - val_accuracy: 0.9908\n",
      "Epoch 233/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3706e-04 - accuracy: 0.9997 - val_loss: 0.0386 - val_accuracy: 0.9908\n",
      "Epoch 234/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3555e-04 - accuracy: 0.9997 - val_loss: 0.0389 - val_accuracy: 0.9908\n",
      "Epoch 235/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3726e-04 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9915\n",
      "Epoch 236/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3552e-04 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 237/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3013e-04 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 238/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.5089e-04 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 239/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.9086e-04 - accuracy: 0.9997 - val_loss: 0.0392 - val_accuracy: 0.9908\n",
      "Epoch 240/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3522e-04 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9908\n",
      "Epoch 241/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.3471e-04 - accuracy: 0.9997 - val_loss: 0.0399 - val_accuracy: 0.9915\n",
      "Epoch 242/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6699e-04 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9923\n",
      "Epoch 243/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3401e-04 - accuracy: 0.9997 - val_loss: 0.0393 - val_accuracy: 0.9915\n",
      "Epoch 244/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3199e-04 - accuracy: 0.9997 - val_loss: 0.0392 - val_accuracy: 0.9915\n",
      "Epoch 245/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2403e-04 - accuracy: 0.9997 - val_loss: 0.0392 - val_accuracy: 0.9915\n",
      "Epoch 246/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3317e-04 - accuracy: 0.9997 - val_loss: 0.0396 - val_accuracy: 0.9915\n",
      "Epoch 247/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3159e-04 - accuracy: 0.9997 - val_loss: 0.0399 - val_accuracy: 0.9915\n",
      "Epoch 248/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3603e-04 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9915\n",
      "Epoch 249/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3984e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9908\n",
      "Epoch 250/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.3780e-04 - accuracy: 0.9997 - val_loss: 0.0402 - val_accuracy: 0.9908\n",
      "Epoch 251/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3010e-04 - accuracy: 0.9997 - val_loss: 0.0404 - val_accuracy: 0.9908\n",
      "Epoch 252/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3883e-04 - accuracy: 0.9997 - val_loss: 0.0407 - val_accuracy: 0.9915\n",
      "Epoch 253/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3410e-04 - accuracy: 0.9997 - val_loss: 0.0407 - val_accuracy: 0.9915\n",
      "Epoch 254/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2192e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9923\n",
      "Epoch 255/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.5582e-04 - accuracy: 0.9997 - val_loss: 0.0405 - val_accuracy: 0.9923\n",
      "Epoch 256/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.7943e-04 - accuracy: 0.9997 - val_loss: 0.0399 - val_accuracy: 0.9908\n",
      "Epoch 257/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.3549e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9908\n",
      "Epoch 258/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.4463e-04 - accuracy: 0.9997 - val_loss: 0.0405 - val_accuracy: 0.9908\n",
      "Epoch 259/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.7025e-04 - accuracy: 0.9997 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
      "Epoch 260/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2101e-04 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9908\n",
      "Epoch 261/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2736e-04 - accuracy: 0.9997 - val_loss: 0.0413 - val_accuracy: 0.9915\n",
      "Epoch 262/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3411e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9908\n",
      "Epoch 263/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1850e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 264/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.5216e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9915\n",
      "Epoch 265/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2482e-04 - accuracy: 0.9997 - val_loss: 0.0410 - val_accuracy: 0.9915\n",
      "Epoch 266/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6789e-04 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9908\n",
      "Epoch 267/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.9536e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9908\n",
      "Epoch 268/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.9563e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9908\n",
      "Epoch 269/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.2241e-04 - accuracy: 0.9997 - val_loss: 0.0416 - val_accuracy: 0.9908\n",
      "Epoch 270/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 6.1740e-04 - accuracy: 0.9997 - val_loss: 0.0419 - val_accuracy: 0.9908\n",
      "Epoch 271/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3573e-04 - accuracy: 0.9997 - val_loss: 0.0418 - val_accuracy: 0.9915\n",
      "Epoch 272/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2795e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 273/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3468e-04 - accuracy: 0.9997 - val_loss: 0.0402 - val_accuracy: 0.9915\n",
      "Epoch 274/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4091e-04 - accuracy: 0.9997 - val_loss: 0.0397 - val_accuracy: 0.9915\n",
      "Epoch 275/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.3690e-04 - accuracy: 0.9997 - val_loss: 0.0394 - val_accuracy: 0.9915\n",
      "Epoch 276/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2623e-04 - accuracy: 0.9997 - val_loss: 0.0393 - val_accuracy: 0.9908\n",
      "Epoch 277/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3675e-04 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9908\n",
      "Epoch 278/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6244e-04 - accuracy: 0.9997 - val_loss: 0.0405 - val_accuracy: 0.9908\n",
      "Epoch 279/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.3730e-04 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
      "Epoch 280/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6801e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9915\n",
      "Epoch 281/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2771e-04 - accuracy: 0.9997 - val_loss: 0.0410 - val_accuracy: 0.9915\n",
      "Epoch 282/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1539e-04 - accuracy: 0.9997 - val_loss: 0.0403 - val_accuracy: 0.9915\n",
      "Epoch 283/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6471e-04 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9915\n",
      "Epoch 284/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2907e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9915\n",
      "Epoch 285/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.2247e-04 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9915\n",
      "Epoch 286/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4313e-04 - accuracy: 0.9997 - val_loss: 0.0403 - val_accuracy: 0.9915\n",
      "Epoch 287/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2473e-04 - accuracy: 0.9997 - val_loss: 0.0407 - val_accuracy: 0.9915\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1725e-04 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
      "Epoch 289/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2689e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9915\n",
      "Epoch 290/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1850e-04 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9915\n",
      "Epoch 291/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1401e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 292/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.2147e-04 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
      "Epoch 293/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2297e-04 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
      "Epoch 294/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.3784e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 295/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.3233e-04 - accuracy: 0.9997 - val_loss: 0.0410 - val_accuracy: 0.9915\n",
      "Epoch 296/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.4167e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9915\n",
      "Epoch 297/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2441e-04 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9915\n",
      "Epoch 298/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.1095e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 299/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.3085e-04 - accuracy: 0.9997 - val_loss: 0.0409 - val_accuracy: 0.9915\n",
      "Epoch 300/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 5.2452e-04 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 300, batch_size = 600, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435db08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9915\n",
      "test loss :  0.041170816868543625\n",
      "test accuracy :  0.9915384650230408\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('test loss : ', score[0])\n",
    "print('test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa406117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      0.98      0.98       320\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "# pred의 값이 0.5 이상인 경우 1로 보겠다\n",
    "pred = pred[0].apply(lambda x : 1 if x >= 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74d519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f2997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae39f9ad",
   "metadata": {},
   "source": [
    "# earlystopping으로 학습 조기 중단 및 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac89bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8330d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ee4e7",
   "metadata": {},
   "source": [
    "# modelcheckpoint\n",
    "- 모델을 중간에 저장하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e2c4a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /model created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "    print(f\"Directory /model created.\")\n",
    "else:\n",
    "    print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62349092",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 0, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa7d90a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 5.3660e-04 - accuracy: 0.9997 - val_loss: 0.0801 - val_accuracy: 0.9923\n",
      "Epoch 2/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 5.0848e-04 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9923\n",
      "Epoch 3/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1690e-04 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9923\n",
      "Epoch 4/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 5.1049e-04 - accuracy: 0.9997 - val_loss: 0.0801 - val_accuracy: 0.9923\n",
      "Epoch 5/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5338e-04 - accuracy: 0.9997 - val_loss: 0.0803 - val_accuracy: 0.9923\n",
      "Epoch 6/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2031e-04 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9923\n",
      "Epoch 7/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 4.9797e-04 - accuracy: 0.9997 - val_loss: 0.0799 - val_accuracy: 0.9923\n",
      "Epoch 8/600\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 5.3696e-04 - accuracy: 0.9997 - val_loss: 0.0799 - val_accuracy: 0.9923\n",
      "Epoch 9/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 5.0607e-04 - accuracy: 0.9997 - val_loss: 0.0797 - val_accuracy: 0.9923\n",
      "Epoch 10/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5439e-04 - accuracy: 0.9997 - val_loss: 0.0802 - val_accuracy: 0.9923\n",
      "Epoch 11/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5376e-04 - accuracy: 0.9997 - val_loss: 0.0808 - val_accuracy: 0.9923\n",
      "Epoch 12/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.9455e-04 - accuracy: 0.9997 - val_loss: 0.0811 - val_accuracy: 0.9923\n",
      "Epoch 13/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5785e-04 - accuracy: 0.9997 - val_loss: 0.0811 - val_accuracy: 0.9915\n",
      "Epoch 14/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 4.9173e-04 - accuracy: 0.9997 - val_loss: 0.0806 - val_accuracy: 0.9923\n",
      "Epoch 15/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1643e-04 - accuracy: 0.9997 - val_loss: 0.0807 - val_accuracy: 0.9923\n",
      "Epoch 16/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0481e-04 - accuracy: 0.9997 - val_loss: 0.0807 - val_accuracy: 0.9923\n",
      "Epoch 17/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0448e-04 - accuracy: 0.9997 - val_loss: 0.0809 - val_accuracy: 0.9923\n",
      "Epoch 18/600\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 5.1853e-04 - accuracy: 0.9997 - val_loss: 0.0816 - val_accuracy: 0.9915\n",
      "Epoch 19/600\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 5.1084e-04 - accuracy: 0.9997 - val_loss: 0.0792 - val_accuracy: 0.9915\n",
      "Epoch 20/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 4.9878e-04 - accuracy: 0.9997 - val_loss: 0.0778 - val_accuracy: 0.9915\n",
      "Epoch 21/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 5.3076e-04 - accuracy: 0.9997 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
      "Epoch 22/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.2970e-04 - accuracy: 0.9997 - val_loss: 0.0775 - val_accuracy: 0.9923\n",
      "Epoch 23/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3461e-04 - accuracy: 0.9997 - val_loss: 0.0777 - val_accuracy: 0.9923\n",
      "Epoch 24/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0013e-04 - accuracy: 0.9997 - val_loss: 0.0779 - val_accuracy: 0.9915\n",
      "Epoch 25/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1440e-04 - accuracy: 0.9997 - val_loss: 0.0777 - val_accuracy: 0.9915\n",
      "Epoch 26/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3053e-04 - accuracy: 0.9997 - val_loss: 0.0777 - val_accuracy: 0.9915\n",
      "Epoch 27/600\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 5.2164e-04 - accuracy: 0.9997 - val_loss: 0.0772 - val_accuracy: 0.9923\n",
      "Epoch 28/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 5.1822e-04 - accuracy: 0.9997 - val_loss: 0.0769 - val_accuracy: 0.9931\n",
      "Epoch 29/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.6109e-04 - accuracy: 0.9997 - val_loss: 0.0774 - val_accuracy: 0.9931\n",
      "Epoch 30/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0666e-04 - accuracy: 0.9997 - val_loss: 0.0783 - val_accuracy: 0.9931\n",
      "Epoch 31/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.9497e-04 - accuracy: 0.9997 - val_loss: 0.0788 - val_accuracy: 0.9915\n",
      "Epoch 32/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0889e-04 - accuracy: 0.9997 - val_loss: 0.0789 - val_accuracy: 0.9915\n",
      "Epoch 33/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3196e-04 - accuracy: 0.9997 - val_loss: 0.0787 - val_accuracy: 0.9915\n",
      "Epoch 34/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.4800e-04 - accuracy: 0.9997 - val_loss: 0.0785 - val_accuracy: 0.9931\n",
      "Epoch 35/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3243e-04 - accuracy: 0.9997 - val_loss: 0.0789 - val_accuracy: 0.9931\n",
      "Epoch 36/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0436e-04 - accuracy: 0.9997 - val_loss: 0.0792 - val_accuracy: 0.9931\n",
      "Epoch 37/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0452e-04 - accuracy: 0.9997 - val_loss: 0.0797 - val_accuracy: 0.9923\n",
      "Epoch 38/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3192e-04 - accuracy: 0.9997 - val_loss: 0.0802 - val_accuracy: 0.9915\n",
      "Epoch 39/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3648e-04 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9915\n",
      "Epoch 40/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1889e-04 - accuracy: 0.9997 - val_loss: 0.0793 - val_accuracy: 0.9923\n",
      "Epoch 41/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0221e-04 - accuracy: 0.9997 - val_loss: 0.0793 - val_accuracy: 0.9931\n",
      "Epoch 42/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0214e-04 - accuracy: 0.9997 - val_loss: 0.0795 - val_accuracy: 0.9931\n",
      "Epoch 43/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3283e-04 - accuracy: 0.9997 - val_loss: 0.0800 - val_accuracy: 0.9923\n",
      "Epoch 44/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.9640e-04 - accuracy: 0.9997 - val_loss: 0.0805 - val_accuracy: 0.9923\n",
      "Epoch 45/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0721e-04 - accuracy: 0.9997 - val_loss: 0.0808 - val_accuracy: 0.9923\n",
      "Epoch 46/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3671e-04 - accuracy: 0.9997 - val_loss: 0.0810 - val_accuracy: 0.9923\n",
      "Epoch 47/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3504e-04 - accuracy: 0.9997 - val_loss: 0.0813 - val_accuracy: 0.9931\n",
      "Epoch 48/600\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 5.4508e-04 - accuracy: 0.9997 - val_loss: 0.0816 - val_accuracy: 0.9923\n",
      "Epoch 49/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2899e-04 - accuracy: 0.9997 - val_loss: 0.0820 - val_accuracy: 0.9923\n",
      "Epoch 50/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0050e-04 - accuracy: 0.9997 - val_loss: 0.0818 - val_accuracy: 0.9923\n",
      "Epoch 51/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0452e-04 - accuracy: 0.9997 - val_loss: 0.0815 - val_accuracy: 0.9923\n",
      "Epoch 52/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0564e-04 - accuracy: 0.9997 - val_loss: 0.0812 - val_accuracy: 0.9923\n",
      "Epoch 53/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.0916e-04 - accuracy: 0.9997 - val_loss: 0.0812 - val_accuracy: 0.9923\n",
      "Epoch 54/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1510e-04 - accuracy: 0.9997 - val_loss: 0.0814 - val_accuracy: 0.9923\n",
      "Epoch 55/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3477e-04 - accuracy: 0.9997 - val_loss: 0.0822 - val_accuracy: 0.9931\n",
      "Epoch 56/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 5.4344e-04 - accuracy: 0.9997 - val_loss: 0.0822 - val_accuracy: 0.9923\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 5.2628e-04 - accuracy: 0.9997 - val_loss: 0.0825 - val_accuracy: 0.9923\n",
      "Epoch 58/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.8663e-04 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9923\n",
      "Epoch 59/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2101e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9923\n",
      "Epoch 60/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1339e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9923\n",
      "Epoch 61/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.1788e-04 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9931\n",
      "Epoch 62/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2057e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9923\n",
      "Epoch 63/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0876e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9923\n",
      "Epoch 64/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.1018e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9931\n",
      "Epoch 65/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2279e-04 - accuracy: 0.9997 - val_loss: 0.0825 - val_accuracy: 0.9931\n",
      "Epoch 66/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.2060e-04 - accuracy: 0.9997 - val_loss: 0.0825 - val_accuracy: 0.9923\n",
      "Epoch 67/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2029e-04 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9923\n",
      "Epoch 68/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3919e-04 - accuracy: 0.9997 - val_loss: 0.0824 - val_accuracy: 0.9931\n",
      "Epoch 69/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.3513e-04 - accuracy: 0.9997 - val_loss: 0.0820 - val_accuracy: 0.9923\n",
      "Epoch 70/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2840e-04 - accuracy: 0.9997 - val_loss: 0.0819 - val_accuracy: 0.9931\n",
      "Epoch 71/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.2534e-04 - accuracy: 0.9997 - val_loss: 0.0820 - val_accuracy: 0.9931\n",
      "Epoch 72/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.5240e-04 - accuracy: 0.9997 - val_loss: 0.0816 - val_accuracy: 0.9923\n",
      "Epoch 73/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.6021e-04 - accuracy: 0.9997 - val_loss: 0.0817 - val_accuracy: 0.9931\n",
      "Epoch 74/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.2776e-04 - accuracy: 0.9997 - val_loss: 0.0815 - val_accuracy: 0.9931\n",
      "Epoch 75/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1362e-04 - accuracy: 0.9997 - val_loss: 0.0817 - val_accuracy: 0.9931\n",
      "Epoch 76/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.1269e-04 - accuracy: 0.9997 - val_loss: 0.0821 - val_accuracy: 0.9931\n",
      "Epoch 77/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.0890e-04 - accuracy: 0.9997 - val_loss: 0.0825 - val_accuracy: 0.9931\n",
      "Epoch 78/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.1286e-04 - accuracy: 0.9997 - val_loss: 0.0824 - val_accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 600, batch_size = 500, validation_data = (X_valid, y_valid), \n",
    "                   callbacks = [early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ace426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ce108f4",
   "metadata": {},
   "source": [
    "# 저장된 베스트 모델을 불러와 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7333aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f12589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/028--0.0769.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77bc251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      0.97      0.98       320\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 11:31:34.878502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x : 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab2496",
   "metadata": {},
   "source": [
    "# 다중분류로 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5139f760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"./data/winequality-white.csv\", sep=\";\")\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da6931bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "717bf871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "752d1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f9361de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(wine.iloc[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0ab4f",
   "metadata": {},
   "source": [
    "X와 y 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "229e398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis = 1)\n",
    "y = wine['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0776d1a",
   "metadata": {},
   "source": [
    "이상치 때문에 robust로 스케일하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ded421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.890244</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>1.658481</td>\n",
       "      <td>-0.947368</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.439024</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.869565</td>\n",
       "      <td>-0.033898</td>\n",
       "      <td>0.059395</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>-0.627119</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>-0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.263158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            0.2          0.090909     0.333333        1.890244   0.142857   \n",
       "1           -0.5          0.363636     0.166667       -0.439024   0.428571   \n",
       "2            1.3          0.181818     0.666667        0.207317   0.500000   \n",
       "3            0.4         -0.272727     0.000000        0.402439   1.071429   \n",
       "4            0.4         -0.272727     0.000000        0.402439   1.071429   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.478261              0.610169  1.658481 -0.947368  -0.142857   \n",
       "1            -0.869565             -0.033898  0.059395  0.631579   0.142857   \n",
       "2            -0.173913             -0.627119  0.310680  0.421053  -0.214286   \n",
       "3             0.565217              0.881356  0.424900  0.052632  -0.500000   \n",
       "4             0.565217              0.881356  0.424900  0.052632  -0.500000   \n",
       "\n",
       "    alcohol  \n",
       "0 -0.842105  \n",
       "1 -0.473684  \n",
       "2 -0.157895  \n",
       "3 -0.263158  \n",
       "4 -0.263158  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c6eaa",
   "metadata": {},
   "source": [
    "y도 다중분류이기 때문에 더미변수로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20bb4572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f33dd8",
   "metadata": {},
   "source": [
    "훈련, valid, 테스트 데이터로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141944f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size = 0.4, stratify = y, random_state = 7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = 0.5, stratify = y_valid, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29fe98",
   "metadata": {},
   "source": [
    "early_stopping이랑 체크포인트 만들어서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bfd39a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 50)\n",
    "modelpath = \"./model/wine_{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 0, save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52062e6",
   "metadata": {},
   "source": [
    "모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f96b1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = X_train.shape[1], activation = 'relu')) # 입력층, input_dim은 독립변수의 컬럼 수\n",
    "model.add(Dense(64, activation = 'relu')) # 은닉층 1\n",
    "model.add(Dense(32, activation = 'relu')) # 은닉층 2\n",
    "model.add(Dense(16, activation = 'relu')) # 은닉층 3\n",
    "model.add(Dense(7, activation = 'softmax')) # 출력층, 이진분류이기 때문에 activation을 sigmoid로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd6a3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,223\n",
      "Trainable params: 5,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41083cf",
   "metadata": {},
   "source": [
    "생성된 모델로 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8583352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.9212 - accuracy: 0.1225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 12:31:20.502881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 12:31:20.556121: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 12:31:20.556179: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 45ms/step - loss: 1.9197 - accuracy: 0.1270 - val_loss: 1.8792 - val_accuracy: 0.2612\n",
      "Epoch 2/600\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 1.8481 - accuracy: 0.3137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 12:31:20.769900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 12:31:20.800763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 12:31:20.800854: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8398 - accuracy: 0.3216 - val_loss: 1.7906 - val_accuracy: 0.3857\n",
      "Epoch 3/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7364 - accuracy: 0.4088 - val_loss: 1.6784 - val_accuracy: 0.4408\n",
      "Epoch 4/600\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6102 - accuracy: 0.4459 - val_loss: 1.5498 - val_accuracy: 0.4490\n",
      "Epoch 5/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4754 - accuracy: 0.4486 - val_loss: 1.4314 - val_accuracy: 0.4490\n",
      "Epoch 6/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3586 - accuracy: 0.4646 - val_loss: 1.3468 - val_accuracy: 0.4786\n",
      "Epoch 7/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2900 - accuracy: 0.5048 - val_loss: 1.3028 - val_accuracy: 0.4847\n",
      "Epoch 8/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2424 - accuracy: 0.5071 - val_loss: 1.2680 - val_accuracy: 0.4929\n",
      "Epoch 9/600\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2108 - accuracy: 0.5187 - val_loss: 1.2413 - val_accuracy: 0.5031\n",
      "Epoch 10/600\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1875 - accuracy: 0.5211 - val_loss: 1.2205 - val_accuracy: 0.5204\n",
      "Epoch 11/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1696 - accuracy: 0.5221 - val_loss: 1.2063 - val_accuracy: 0.5133\n",
      "Epoch 12/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1537 - accuracy: 0.5347 - val_loss: 1.1924 - val_accuracy: 0.5245\n",
      "Epoch 13/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1413 - accuracy: 0.5402 - val_loss: 1.1809 - val_accuracy: 0.5214\n",
      "Epoch 14/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1284 - accuracy: 0.5497 - val_loss: 1.1690 - val_accuracy: 0.5408\n",
      "Epoch 15/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1171 - accuracy: 0.5545 - val_loss: 1.1584 - val_accuracy: 0.5429\n",
      "Epoch 16/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1054 - accuracy: 0.5558 - val_loss: 1.1496 - val_accuracy: 0.5378\n",
      "Epoch 17/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0962 - accuracy: 0.5599 - val_loss: 1.1420 - val_accuracy: 0.5347\n",
      "Epoch 18/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0864 - accuracy: 0.5558 - val_loss: 1.1353 - val_accuracy: 0.5347\n",
      "Epoch 19/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0784 - accuracy: 0.5654 - val_loss: 1.1277 - val_accuracy: 0.5306\n",
      "Epoch 20/600\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0708 - accuracy: 0.5623 - val_loss: 1.1252 - val_accuracy: 0.5327\n",
      "Epoch 21/600\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.0643 - accuracy: 0.5630 - val_loss: 1.1189 - val_accuracy: 0.5347\n",
      "Epoch 22/600\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0566 - accuracy: 0.5616 - val_loss: 1.1161 - val_accuracy: 0.5337\n",
      "Epoch 23/600\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 1.0505 - accuracy: 0.5650 - val_loss: 1.1118 - val_accuracy: 0.5378\n",
      "Epoch 24/600\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0444 - accuracy: 0.5684 - val_loss: 1.1093 - val_accuracy: 0.5388\n",
      "Epoch 25/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0397 - accuracy: 0.5640 - val_loss: 1.1054 - val_accuracy: 0.5388\n",
      "Epoch 26/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0337 - accuracy: 0.5694 - val_loss: 1.1035 - val_accuracy: 0.5398\n",
      "Epoch 27/600\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0290 - accuracy: 0.5674 - val_loss: 1.0997 - val_accuracy: 0.5337\n",
      "Epoch 28/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0242 - accuracy: 0.5732 - val_loss: 1.0961 - val_accuracy: 0.5418\n",
      "Epoch 29/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0203 - accuracy: 0.5759 - val_loss: 1.0959 - val_accuracy: 0.5378\n",
      "Epoch 30/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0189 - accuracy: 0.5752 - val_loss: 1.0952 - val_accuracy: 0.5429\n",
      "Epoch 31/600\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0132 - accuracy: 0.5793 - val_loss: 1.0926 - val_accuracy: 0.5408\n",
      "Epoch 32/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0096 - accuracy: 0.5820 - val_loss: 1.0951 - val_accuracy: 0.5398\n",
      "Epoch 33/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0089 - accuracy: 0.5834 - val_loss: 1.0909 - val_accuracy: 0.5306\n",
      "Epoch 34/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9994 - accuracy: 0.5865 - val_loss: 1.0889 - val_accuracy: 0.5439\n",
      "Epoch 35/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9980 - accuracy: 0.5875 - val_loss: 1.0840 - val_accuracy: 0.5327\n",
      "Epoch 36/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9950 - accuracy: 0.5895 - val_loss: 1.0814 - val_accuracy: 0.5520\n",
      "Epoch 37/600\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9897 - accuracy: 0.5929 - val_loss: 1.0797 - val_accuracy: 0.5510\n",
      "Epoch 38/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9884 - accuracy: 0.5892 - val_loss: 1.0784 - val_accuracy: 0.5378\n",
      "Epoch 39/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9806 - accuracy: 0.5956 - val_loss: 1.0778 - val_accuracy: 0.5510\n",
      "Epoch 40/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9777 - accuracy: 0.5987 - val_loss: 1.0771 - val_accuracy: 0.5337\n",
      "Epoch 41/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9737 - accuracy: 0.5994 - val_loss: 1.0777 - val_accuracy: 0.5490\n",
      "Epoch 42/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9739 - accuracy: 0.5987 - val_loss: 1.0737 - val_accuracy: 0.5429\n",
      "Epoch 43/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9680 - accuracy: 0.6014 - val_loss: 1.0737 - val_accuracy: 0.5490\n",
      "Epoch 44/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9660 - accuracy: 0.5953 - val_loss: 1.0728 - val_accuracy: 0.5480\n",
      "Epoch 45/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9619 - accuracy: 0.5984 - val_loss: 1.0714 - val_accuracy: 0.5408\n",
      "Epoch 46/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9588 - accuracy: 0.5980 - val_loss: 1.0682 - val_accuracy: 0.5469\n",
      "Epoch 47/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9558 - accuracy: 0.6052 - val_loss: 1.0688 - val_accuracy: 0.5408\n",
      "Epoch 48/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9541 - accuracy: 0.6004 - val_loss: 1.0742 - val_accuracy: 0.5500\n",
      "Epoch 49/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9525 - accuracy: 0.6103 - val_loss: 1.0718 - val_accuracy: 0.5286\n",
      "Epoch 50/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9506 - accuracy: 0.6028 - val_loss: 1.0669 - val_accuracy: 0.5500\n",
      "Epoch 51/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9447 - accuracy: 0.6035 - val_loss: 1.0646 - val_accuracy: 0.5520\n",
      "Epoch 52/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9422 - accuracy: 0.6031 - val_loss: 1.0649 - val_accuracy: 0.5388\n",
      "Epoch 53/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9406 - accuracy: 0.6042 - val_loss: 1.0632 - val_accuracy: 0.5490\n",
      "Epoch 54/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9379 - accuracy: 0.6096 - val_loss: 1.0624 - val_accuracy: 0.5490\n",
      "Epoch 55/600\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9333 - accuracy: 0.6076 - val_loss: 1.0619 - val_accuracy: 0.5418\n",
      "Epoch 56/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9315 - accuracy: 0.6127 - val_loss: 1.0627 - val_accuracy: 0.5469\n",
      "Epoch 57/600\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9297 - accuracy: 0.6089 - val_loss: 1.0602 - val_accuracy: 0.5449\n",
      "Epoch 58/600\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9263 - accuracy: 0.6082 - val_loss: 1.0599 - val_accuracy: 0.5418\n",
      "Epoch 59/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9238 - accuracy: 0.6106 - val_loss: 1.0604 - val_accuracy: 0.5469\n",
      "Epoch 60/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9215 - accuracy: 0.6150 - val_loss: 1.0582 - val_accuracy: 0.5490\n",
      "Epoch 61/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9206 - accuracy: 0.6103 - val_loss: 1.0623 - val_accuracy: 0.5480\n",
      "Epoch 62/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9159 - accuracy: 0.6130 - val_loss: 1.0619 - val_accuracy: 0.5367\n",
      "Epoch 63/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9175 - accuracy: 0.6137 - val_loss: 1.0612 - val_accuracy: 0.5480\n",
      "Epoch 64/600\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9131 - accuracy: 0.6167 - val_loss: 1.0594 - val_accuracy: 0.5378\n",
      "Epoch 65/600\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9121 - accuracy: 0.6157 - val_loss: 1.0595 - val_accuracy: 0.5480\n",
      "Epoch 66/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9092 - accuracy: 0.6181 - val_loss: 1.0617 - val_accuracy: 0.5469\n",
      "Epoch 67/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9034 - accuracy: 0.6181 - val_loss: 1.0590 - val_accuracy: 0.5429\n",
      "Epoch 68/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9022 - accuracy: 0.6181 - val_loss: 1.0593 - val_accuracy: 0.5490\n",
      "Epoch 69/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9013 - accuracy: 0.6174 - val_loss: 1.0614 - val_accuracy: 0.5459\n",
      "Epoch 70/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8967 - accuracy: 0.6222 - val_loss: 1.0604 - val_accuracy: 0.5510\n",
      "Epoch 71/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8937 - accuracy: 0.6276 - val_loss: 1.0603 - val_accuracy: 0.5490\n",
      "Epoch 72/600\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8925 - accuracy: 0.6246 - val_loss: 1.0628 - val_accuracy: 0.5490\n",
      "Epoch 73/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8921 - accuracy: 0.6249 - val_loss: 1.0617 - val_accuracy: 0.5459\n",
      "Epoch 74/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8879 - accuracy: 0.6290 - val_loss: 1.0593 - val_accuracy: 0.5551\n",
      "Epoch 75/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8859 - accuracy: 0.6263 - val_loss: 1.0618 - val_accuracy: 0.5459\n",
      "Epoch 76/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8845 - accuracy: 0.6276 - val_loss: 1.0619 - val_accuracy: 0.5531\n",
      "Epoch 77/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8820 - accuracy: 0.6270 - val_loss: 1.0637 - val_accuracy: 0.5490\n",
      "Epoch 78/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8785 - accuracy: 0.6270 - val_loss: 1.0632 - val_accuracy: 0.5469\n",
      "Epoch 79/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8774 - accuracy: 0.6249 - val_loss: 1.0643 - val_accuracy: 0.5561\n",
      "Epoch 80/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8785 - accuracy: 0.6276 - val_loss: 1.0659 - val_accuracy: 0.5510\n",
      "Epoch 81/600\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8716 - accuracy: 0.6372 - val_loss: 1.0620 - val_accuracy: 0.5561\n",
      "Epoch 82/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8696 - accuracy: 0.6300 - val_loss: 1.0639 - val_accuracy: 0.5592\n",
      "Epoch 83/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.6361 - val_loss: 1.0717 - val_accuracy: 0.5510\n",
      "Epoch 84/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8748 - accuracy: 0.6368 - val_loss: 1.0664 - val_accuracy: 0.5633\n",
      "Epoch 85/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8625 - accuracy: 0.6372 - val_loss: 1.0756 - val_accuracy: 0.5510\n",
      "Epoch 86/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8640 - accuracy: 0.6382 - val_loss: 1.0636 - val_accuracy: 0.5592\n",
      "Epoch 87/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8602 - accuracy: 0.6321 - val_loss: 1.0667 - val_accuracy: 0.5582\n",
      "Epoch 88/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8567 - accuracy: 0.6430 - val_loss: 1.0657 - val_accuracy: 0.5571\n",
      "Epoch 89/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8568 - accuracy: 0.6396 - val_loss: 1.0656 - val_accuracy: 0.5582\n",
      "Epoch 90/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8512 - accuracy: 0.6406 - val_loss: 1.0674 - val_accuracy: 0.5531\n",
      "Epoch 91/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8484 - accuracy: 0.6389 - val_loss: 1.0670 - val_accuracy: 0.5541\n",
      "Epoch 92/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8486 - accuracy: 0.6385 - val_loss: 1.0720 - val_accuracy: 0.5510\n",
      "Epoch 93/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8478 - accuracy: 0.6450 - val_loss: 1.0631 - val_accuracy: 0.5571\n",
      "Epoch 94/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8467 - accuracy: 0.6460 - val_loss: 1.0723 - val_accuracy: 0.5612\n",
      "Epoch 95/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8421 - accuracy: 0.6436 - val_loss: 1.0785 - val_accuracy: 0.5531\n",
      "Epoch 96/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8454 - accuracy: 0.6477 - val_loss: 1.0633 - val_accuracy: 0.5694\n",
      "Epoch 97/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8415 - accuracy: 0.6464 - val_loss: 1.0715 - val_accuracy: 0.5622\n",
      "Epoch 98/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8376 - accuracy: 0.6392 - val_loss: 1.0702 - val_accuracy: 0.5592\n",
      "Epoch 99/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8340 - accuracy: 0.6504 - val_loss: 1.0703 - val_accuracy: 0.5663\n",
      "Epoch 100/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8342 - accuracy: 0.6453 - val_loss: 1.0824 - val_accuracy: 0.5561\n",
      "Epoch 101/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8319 - accuracy: 0.6498 - val_loss: 1.0700 - val_accuracy: 0.5724\n",
      "Epoch 102/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8315 - accuracy: 0.6552 - val_loss: 1.0810 - val_accuracy: 0.5602\n",
      "Epoch 103/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8287 - accuracy: 0.6477 - val_loss: 1.0752 - val_accuracy: 0.5561\n",
      "Epoch 104/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8240 - accuracy: 0.6532 - val_loss: 1.0752 - val_accuracy: 0.5704\n",
      "Epoch 105/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8210 - accuracy: 0.6528 - val_loss: 1.0791 - val_accuracy: 0.5592\n",
      "Epoch 106/600\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8254 - accuracy: 0.6501 - val_loss: 1.0747 - val_accuracy: 0.5622\n",
      "Epoch 107/600\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8187 - accuracy: 0.6613 - val_loss: 1.0737 - val_accuracy: 0.5643\n",
      "Epoch 108/600\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8149 - accuracy: 0.6583 - val_loss: 1.0791 - val_accuracy: 0.5571\n",
      "Epoch 109/600\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8120 - accuracy: 0.6596 - val_loss: 1.0795 - val_accuracy: 0.5684\n",
      "Epoch 110/600\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8099 - accuracy: 0.6603 - val_loss: 1.0780 - val_accuracy: 0.5643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 600, batch_size = 400, validation_data = (X_valid, y_valid), \n",
    "                   callbacks = [early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69634d3d",
   "metadata": {},
   "source": [
    "최고 좋은 모델로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8656cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/wine_060--1.0582.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "682cea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       1.00      0.06      0.11        33\n",
      "           2       0.65      0.55      0.59       291\n",
      "           3       0.60      0.57      0.58       440\n",
      "           4       0.57      0.34      0.42       176\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.61      0.48      0.54       980\n",
      "   macro avg       0.40      0.22      0.24       980\n",
      "weighted avg       0.60      0.48      0.52       980\n",
      " samples avg       0.48      0.48      0.48       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 12:32:56.534941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred, columns = y.columns)\n",
    "for i in best_pred :\n",
    "    best_pred[i] = best_pred[i].apply(lambda x : True if x > 0.5 else False)\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53e534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949b592b",
   "metadata": {},
   "source": [
    "함수형으로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72b53a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 1.9285 - accuracy: 0.0949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 12:15:05.434077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 12:15:05.487433: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 12:15:05.487498: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 29ms/step - loss: 1.8952 - accuracy: 0.1722 - val_loss: 1.8194 - val_accuracy: 0.3612\n",
      "Epoch 2/400\n",
      " 5/12 [===========>..................] - ETA: 0s - loss: 1.7837 - accuracy: 0.3880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 12:15:05.723063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 12:15:05.749902: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 12:15:05.749975: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14853 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 21ms/step - loss: 1.7287 - accuracy: 0.4170 - val_loss: 1.6326 - val_accuracy: 0.4541\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 1.5243 - accuracy: 0.4595 - val_loss: 1.4405 - val_accuracy: 0.4571\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.3606 - accuracy: 0.4769 - val_loss: 1.3493 - val_accuracy: 0.4776\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.2839 - accuracy: 0.4912 - val_loss: 1.3087 - val_accuracy: 0.4878\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.2403 - accuracy: 0.5034 - val_loss: 1.2761 - val_accuracy: 0.5010\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.2031 - accuracy: 0.5197 - val_loss: 1.2528 - val_accuracy: 0.5102\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.1735 - accuracy: 0.5374 - val_loss: 1.2273 - val_accuracy: 0.5122\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.1475 - accuracy: 0.5483 - val_loss: 1.2042 - val_accuracy: 0.5204\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.1265 - accuracy: 0.5619 - val_loss: 1.1831 - val_accuracy: 0.5194\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.1068 - accuracy: 0.5548 - val_loss: 1.1620 - val_accuracy: 0.5265\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.0886 - accuracy: 0.5688 - val_loss: 1.1450 - val_accuracy: 0.5347\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.0776 - accuracy: 0.5643 - val_loss: 1.1360 - val_accuracy: 0.5245\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.0677 - accuracy: 0.5715 - val_loss: 1.1237 - val_accuracy: 0.5347\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.0544 - accuracy: 0.5705 - val_loss: 1.1145 - val_accuracy: 0.5296\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.0454 - accuracy: 0.5725 - val_loss: 1.1129 - val_accuracy: 0.5388\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.0378 - accuracy: 0.5654 - val_loss: 1.1041 - val_accuracy: 0.5418\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0294 - accuracy: 0.5715 - val_loss: 1.1028 - val_accuracy: 0.5286\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.0201 - accuracy: 0.5783 - val_loss: 1.0972 - val_accuracy: 0.5449\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.0133 - accuracy: 0.5711 - val_loss: 1.0904 - val_accuracy: 0.5296\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.0067 - accuracy: 0.5800 - val_loss: 1.0876 - val_accuracy: 0.5347\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 1.0024 - accuracy: 0.5834 - val_loss: 1.0834 - val_accuracy: 0.5429\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.9946 - accuracy: 0.5837 - val_loss: 1.0818 - val_accuracy: 0.5388\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.9905 - accuracy: 0.5865 - val_loss: 1.0795 - val_accuracy: 0.5388\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.9863 - accuracy: 0.5813 - val_loss: 1.0763 - val_accuracy: 0.5449\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.9799 - accuracy: 0.5888 - val_loss: 1.0744 - val_accuracy: 0.5398\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9778 - accuracy: 0.5909 - val_loss: 1.0710 - val_accuracy: 0.5459\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.9698 - accuracy: 0.5926 - val_loss: 1.0664 - val_accuracy: 0.5582\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9689 - accuracy: 0.5895 - val_loss: 1.0647 - val_accuracy: 0.5459\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.9605 - accuracy: 0.5933 - val_loss: 1.0650 - val_accuracy: 0.5500\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9566 - accuracy: 0.5939 - val_loss: 1.0661 - val_accuracy: 0.5388\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.9511 - accuracy: 0.6028 - val_loss: 1.0614 - val_accuracy: 0.5622\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.9465 - accuracy: 0.6042 - val_loss: 1.0590 - val_accuracy: 0.5551\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9450 - accuracy: 0.5997 - val_loss: 1.0590 - val_accuracy: 0.5449\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.9377 - accuracy: 0.6062 - val_loss: 1.0625 - val_accuracy: 0.5622\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.9334 - accuracy: 0.6086 - val_loss: 1.0530 - val_accuracy: 0.5408\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.9279 - accuracy: 0.6086 - val_loss: 1.0637 - val_accuracy: 0.5388\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9312 - accuracy: 0.6116 - val_loss: 1.0543 - val_accuracy: 0.5531\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9249 - accuracy: 0.6167 - val_loss: 1.0538 - val_accuracy: 0.5388\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.9204 - accuracy: 0.6096 - val_loss: 1.0543 - val_accuracy: 0.5582\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.9176 - accuracy: 0.6089 - val_loss: 1.0590 - val_accuracy: 0.5255\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.9166 - accuracy: 0.6188 - val_loss: 1.0496 - val_accuracy: 0.5490\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9119 - accuracy: 0.6167 - val_loss: 1.0603 - val_accuracy: 0.5347\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.9088 - accuracy: 0.6164 - val_loss: 1.0500 - val_accuracy: 0.5561\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.9022 - accuracy: 0.6188 - val_loss: 1.0524 - val_accuracy: 0.5520\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.8992 - accuracy: 0.6198 - val_loss: 1.0459 - val_accuracy: 0.5469\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.8929 - accuracy: 0.6225 - val_loss: 1.0467 - val_accuracy: 0.5510\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.8887 - accuracy: 0.6253 - val_loss: 1.0455 - val_accuracy: 0.5510\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8867 - accuracy: 0.6273 - val_loss: 1.0491 - val_accuracy: 0.5510\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8848 - accuracy: 0.6225 - val_loss: 1.0489 - val_accuracy: 0.5490\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8785 - accuracy: 0.6287 - val_loss: 1.0528 - val_accuracy: 0.5378\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8800 - accuracy: 0.6270 - val_loss: 1.0489 - val_accuracy: 0.5510\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.8763 - accuracy: 0.6215 - val_loss: 1.0490 - val_accuracy: 0.5469\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.8699 - accuracy: 0.6297 - val_loss: 1.0500 - val_accuracy: 0.5459\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.8684 - accuracy: 0.6355 - val_loss: 1.0480 - val_accuracy: 0.5531\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.8658 - accuracy: 0.6310 - val_loss: 1.0484 - val_accuracy: 0.5449\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.8598 - accuracy: 0.6399 - val_loss: 1.0503 - val_accuracy: 0.5398\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.8555 - accuracy: 0.6365 - val_loss: 1.0524 - val_accuracy: 0.5449\n",
      "Epoch 59/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 19ms/step - loss: 0.8533 - accuracy: 0.6378 - val_loss: 1.0518 - val_accuracy: 0.5449\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.8520 - accuracy: 0.6321 - val_loss: 1.0535 - val_accuracy: 0.5378\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.8527 - accuracy: 0.6378 - val_loss: 1.0525 - val_accuracy: 0.5347\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8452 - accuracy: 0.6396 - val_loss: 1.0566 - val_accuracy: 0.5439\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8398 - accuracy: 0.6457 - val_loss: 1.0540 - val_accuracy: 0.5418\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8382 - accuracy: 0.6440 - val_loss: 1.0551 - val_accuracy: 0.5418\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8343 - accuracy: 0.6460 - val_loss: 1.0589 - val_accuracy: 0.5459\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8320 - accuracy: 0.6491 - val_loss: 1.0606 - val_accuracy: 0.5469\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8303 - accuracy: 0.6470 - val_loss: 1.0568 - val_accuracy: 0.5367\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8287 - accuracy: 0.6484 - val_loss: 1.0640 - val_accuracy: 0.5388\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8294 - accuracy: 0.6477 - val_loss: 1.0608 - val_accuracy: 0.5337\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8197 - accuracy: 0.6566 - val_loss: 1.0663 - val_accuracy: 0.5357\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8176 - accuracy: 0.6518 - val_loss: 1.0650 - val_accuracy: 0.5388\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8152 - accuracy: 0.6566 - val_loss: 1.0597 - val_accuracy: 0.5490\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8100 - accuracy: 0.6576 - val_loss: 1.0632 - val_accuracy: 0.5531\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8057 - accuracy: 0.6572 - val_loss: 1.0655 - val_accuracy: 0.5265\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.8066 - accuracy: 0.6641 - val_loss: 1.0658 - val_accuracy: 0.5439\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8026 - accuracy: 0.6586 - val_loss: 1.0738 - val_accuracy: 0.5398\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8001 - accuracy: 0.6637 - val_loss: 1.0745 - val_accuracy: 0.5398\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7952 - accuracy: 0.6627 - val_loss: 1.0635 - val_accuracy: 0.5449\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7934 - accuracy: 0.6668 - val_loss: 1.0744 - val_accuracy: 0.5582\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7950 - accuracy: 0.6583 - val_loss: 1.0722 - val_accuracy: 0.5602\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7892 - accuracy: 0.6647 - val_loss: 1.0735 - val_accuracy: 0.5490\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7863 - accuracy: 0.6654 - val_loss: 1.0812 - val_accuracy: 0.5449\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7851 - accuracy: 0.6681 - val_loss: 1.0819 - val_accuracy: 0.5622\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7800 - accuracy: 0.6709 - val_loss: 1.0729 - val_accuracy: 0.5531\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7741 - accuracy: 0.6726 - val_loss: 1.0773 - val_accuracy: 0.5490\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7718 - accuracy: 0.6722 - val_loss: 1.0842 - val_accuracy: 0.5622\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7714 - accuracy: 0.6681 - val_loss: 1.0772 - val_accuracy: 0.5388\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7693 - accuracy: 0.6814 - val_loss: 1.0892 - val_accuracy: 0.5367\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7670 - accuracy: 0.6835 - val_loss: 1.0868 - val_accuracy: 0.5520\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7634 - accuracy: 0.6763 - val_loss: 1.0803 - val_accuracy: 0.5551\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7687 - accuracy: 0.6780 - val_loss: 1.1081 - val_accuracy: 0.5265\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7615 - accuracy: 0.6787 - val_loss: 1.0864 - val_accuracy: 0.5510\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7515 - accuracy: 0.6872 - val_loss: 1.0887 - val_accuracy: 0.5500\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7479 - accuracy: 0.6818 - val_loss: 1.0961 - val_accuracy: 0.5408\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7506 - accuracy: 0.6899 - val_loss: 1.0965 - val_accuracy: 0.5347\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7496 - accuracy: 0.6862 - val_loss: 1.0991 - val_accuracy: 0.5490\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7451 - accuracy: 0.6852 - val_loss: 1.0995 - val_accuracy: 0.5694\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7453 - accuracy: 0.6926 - val_loss: 1.1052 - val_accuracy: 0.5602\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "inputs = Input(shape = (X_train.shape[1], )) # 입력층 정의 input(shape=(독립변수 수, ))\n",
    "x = Dense(32, activation = 'relu')(inputs) # 은닉층 1번\n",
    "x = Dense(64, activation = 'relu')(x) # 은닉층 2번\n",
    "x = Dense(32, activation = 'relu')(x) # 은닉층 3번\n",
    "x = Dense(16, activation = 'relu')(x) # 은닉층 4번\n",
    "x = Dense(7, activation = 'softmax')(x) # 출력층\n",
    "model = Model(inputs, x)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 400, batch_size = 250, validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa9157",
   "metadata": {},
   "source": [
    "최고 좋은 모델로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ef0d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/wine_048--1.0455.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "141d460b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.089581</td>\n",
       "      <td>0.860499</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.208834</td>\n",
       "      <td>0.638722</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.664453</td>\n",
       "      <td>0.306594</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.049320</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.241372</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.395435</td>\n",
       "      <td>0.567951</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>0.296632</td>\n",
       "      <td>0.671045</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.059407</td>\n",
       "      <td>0.718620</td>\n",
       "      <td>0.218647</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.251113</td>\n",
       "      <td>0.589353</td>\n",
       "      <td>0.154972</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.131681</td>\n",
       "      <td>0.431964</td>\n",
       "      <td>0.370644</td>\n",
       "      <td>0.054835</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.283820</td>\n",
       "      <td>0.525646</td>\n",
       "      <td>0.151614</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         4         5         6         7         8         9\n",
       "0    0.000094  0.005566  0.089581  0.860499  0.041013  0.003208  0.000041\n",
       "1    0.000363  0.002011  0.047012  0.208834  0.638722  0.102426  0.000633\n",
       "2    0.000276  0.023805  0.664453  0.306594  0.004739  0.000122  0.000010\n",
       "3    0.001663  0.049320  0.704784  0.241372  0.002508  0.000317  0.000035\n",
       "4    0.000554  0.015535  0.395435  0.567951  0.018386  0.002057  0.000082\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.000477  0.011268  0.296632  0.671045  0.018455  0.002072  0.000052\n",
       "976  0.002223  0.059407  0.718620  0.218647  0.000994  0.000099  0.000010\n",
       "977  0.003563  0.251113  0.589353  0.154972  0.000852  0.000114  0.000033\n",
       "978  0.001046  0.008531  0.131681  0.431964  0.370644  0.054835  0.001299\n",
       "979  0.000975  0.002719  0.034313  0.283820  0.525646  0.151614  0.000912\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred, columns = y.columns)\n",
    "best_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aab51422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in best_pred :\n",
    "    best_pred[i] = best_pred[i].apply(lambda x : True if x > 0.5 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3f275b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         3      4      5      6      7      8      9\n",
       "0    False  False  False   True  False  False  False\n",
       "1    False  False  False  False   True  False  False\n",
       "2    False  False   True  False  False  False  False\n",
       "3    False  False   True  False  False  False  False\n",
       "4    False  False  False   True  False  False  False\n",
       "..     ...    ...    ...    ...    ...    ...    ...\n",
       "975  False  False  False   True  False  False  False\n",
       "976  False  False   True  False  False  False  False\n",
       "977  False  False   True  False  False  False  False\n",
       "978  False  False  False  False  False  False  False\n",
       "979  False  False  False  False   True  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8fba7357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        33\n",
      "           2       0.65      0.55      0.60       291\n",
      "           3       0.58      0.53      0.55       440\n",
      "           4       0.50      0.31      0.38       176\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.59      0.46      0.52       980\n",
      "   macro avg       0.25      0.20      0.22       980\n",
      "weighted avg       0.54      0.46      0.50       980\n",
      " samples avg       0.46      0.46      0.46       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83480a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05664680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8532f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d33dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3847d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
