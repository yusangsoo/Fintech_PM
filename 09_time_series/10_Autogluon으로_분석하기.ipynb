{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ab5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121e033",
   "metadata": {},
   "source": [
    "# Autogluon 기본 사용법\n",
    "1. 데이터 로딩\n",
    "2. 타겟변수 지정\n",
    "3. TabularPredictor 설정(타겟변수, 모델 성능 지표) - 모델 설정\n",
    "4. 훈련(데이터, 제한시간설정, 분석사전 설정 지정) - .fit()\n",
    "5. 데이터에서 일부 데이터를 테스트 데이터로 추출 - .sample()\n",
    "6. 분석이 끝난 모델로 테스트 데이터에서 추론 - .predict()\n",
    "7. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c10664",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcc1246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education  ...  hours-per-week  native-country   class\n",
       "0   25     Private           11th  ...              40   United-States   <=50K\n",
       "1   38     Private        HS-grad  ...              50   United-States   <=50K\n",
       "2   28   Local-gov     Assoc-acdm  ...              40   United-States    >50K\n",
       "3   44     Private   Some-college  ...              40   United-States    >50K\n",
       "4   18         NaN   Some-college  ...              30   United-States   <=50K\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/salary2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77834312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7905f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, stratify = data['class'], test_size = 0.4, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32e1a2",
   "metadata": {},
   "source": [
    "## 2. 타겟변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6031510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e9d8e",
   "metadata": {},
   "source": [
    "## 3. 제한시간, 검정지표(accuracy, rmse, roc_auc) 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c555c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = 300 # 300초 설정하기\n",
    "metric = 'accuracy' # 성능지표(f1, recall, roc_auc_score 등등. 적을 땐 풀네임으로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3261b",
   "metadata": {},
   "source": [
    "## 4. 모델정의 TablularPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43cd50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_024017\"\n"
     ]
    }
   ],
   "source": [
    "model = TabularPredictor(label = target_column, eval_metric = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8514487",
   "metadata": {},
   "source": [
    "## 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0b2a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          12\n",
      "Memory Avail:       13.57 GB / 15.32 GB (88.5%)\n",
      "Disk Space Avail:   94.86 GB / 237.85 GB (39.9%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_024017\"\n",
      "Train Data Rows:    29305\n",
      "Train Data Columns: 13\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13908.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08530967411704488, Train Rows: 26805, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.78s of the 299.77s of remaining time.\n",
      "\t0.8272\t = Validation score   (accuracy)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 297.91s of the 297.91s of remaining time.\n",
      "\t0.8252\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 297.76s of the 297.76s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "\t0.8652\t = Validation score   (accuracy)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 296.4s of the 296.4s of remaining time.\n",
      "\t0.8728\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 295.7s of the 295.7s of remaining time.\n",
      "\t0.846\t = Validation score   (accuracy)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 293.0s of the 293.0s of remaining time.\n",
      "\t0.8424\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 290.5s of the 290.5s of remaining time.\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n",
      "\t0.872\t = Validation score   (accuracy)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 286.06s of the 286.06s of remaining time.\n",
      "\t0.8372\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 283.22s of the 283.22s of remaining time.\n",
      "\t0.838\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 280.33s of the 280.33s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t0.8584\t = Validation score   (accuracy)\n",
      "\t237.15s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 41.94s of the 41.94s of remaining time.\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 40.77s of the 40.77s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t30.08s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 9.37s of the 9.37s of remaining time.\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.78s of the 8.29s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.87, 'LightGBM': 0.087, 'NeuralNetFastAI': 0.043}\n",
      "\t0.8784\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 291.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2057.5 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_024017\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f5d399f85e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, time_limit = time_limit, presets = ['medium_quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f952041",
   "metadata": {},
   "source": [
    "## 6. 생성된 모델에 테스트 데이터 넣어 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ba2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa8c2612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14235     <=50K\n",
       "28608      >50K\n",
       "16506     <=50K\n",
       "7311      <=50K\n",
       "23094     <=50K\n",
       "          ...  \n",
       "9697       >50K\n",
       "20656     <=50K\n",
       "39937     <=50K\n",
       "2502      <=50K\n",
       "18868      >50K\n",
       "Name: class, Length: 19537, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ede8eb",
   "metadata": {},
   "source": [
    "## 7. 모델 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a38b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t148.87s\t= Expected runtime (29.77s per shuffle set)\n",
      "\t145.73s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data)\n",
    "result_df = pd.DataFrame([result], index = [0])\n",
    "# 여러 모델 성능 비교\n",
    "leader_board = model.leaderboard(test_data)\n",
    "# 중요 변수 출력\n",
    "feature_importance = model.feature_importance(test_data)\n",
    "best_model_name = model.model_best\n",
    "# best 모델 로딩\n",
    "best_model = model._trainer.load_model(best_model_name)\n",
    "# 파라미터 확인\n",
    "best_model_params = best_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb331d",
   "metadata": {},
   "source": [
    "## 8. 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b318ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result_df ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87516</td>\n",
       "      <td>0.798891</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>0.930933</td>\n",
       "      <td>0.714436</td>\n",
       "      <td>0.789188</td>\n",
       "      <td>0.65262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy       mcc  ...        f1  precision   recall\n",
       "0   0.87516           0.798891  0.640167  ...  0.714436   0.789188  0.65262\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== leader_board ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875160</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>8.066276</td>\n",
       "      <td>1.215091</td>\n",
       "      <td>239.038045</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.119031</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.875006</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.082606</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>1.117751</td>\n",
       "      <td>0.082606</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>1.117751</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.874187</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>4.417121</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>4.417121</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.873932</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.654504</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.654504</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.872242</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.047844</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.977769</td>\n",
       "      <td>0.047844</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.977769</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.864360</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>1.323138</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>1.323138</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.854532</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>7.944167</td>\n",
       "      <td>1.198027</td>\n",
       "      <td>237.146759</td>\n",
       "      <td>7.944167</td>\n",
       "      <td>1.198027</td>\n",
       "      <td>237.146759</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.851359</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.138604</td>\n",
       "      <td>0.114760</td>\n",
       "      <td>1.453418</td>\n",
       "      <td>1.138604</td>\n",
       "      <td>0.114760</td>\n",
       "      <td>1.453418</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.851308</td>\n",
       "      <td>0.8424</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.069191</td>\n",
       "      <td>0.112392</td>\n",
       "      <td>1.314699</td>\n",
       "      <td>1.069191</td>\n",
       "      <td>0.112392</td>\n",
       "      <td>1.314699</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.847418</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.782945</td>\n",
       "      <td>0.122434</td>\n",
       "      <td>1.279069</td>\n",
       "      <td>1.782945</td>\n",
       "      <td>0.122434</td>\n",
       "      <td>1.279069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.846548</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.379817</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>1.241116</td>\n",
       "      <td>1.379817</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>1.241116</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.838665</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>9.862139</td>\n",
       "      <td>1.286671</td>\n",
       "      <td>30.080931</td>\n",
       "      <td>9.862139</td>\n",
       "      <td>1.286671</td>\n",
       "      <td>30.080931</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.825050</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.469704</td>\n",
       "      <td>0.088264</td>\n",
       "      <td>1.729627</td>\n",
       "      <td>0.469704</td>\n",
       "      <td>0.088264</td>\n",
       "      <td>1.729627</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.821569</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.561726</td>\n",
       "      <td>0.071633</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>0.561726</td>\n",
       "      <td>0.071633</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  ...  can_infer fit_order\n",
       "0   WeightedEnsemble_L2    0.875160  ...       True        14\n",
       "1               XGBoost    0.875006  ...       True        11\n",
       "2              CatBoost    0.874187  ...       True         7\n",
       "3              LightGBM    0.873932  ...       True         4\n",
       "4         LightGBMLarge    0.872242  ...       True        13\n",
       "5            LightGBMXT    0.864360  ...       True         3\n",
       "6       NeuralNetFastAI    0.854532  ...       True        10\n",
       "7      RandomForestGini    0.851359  ...       True         5\n",
       "8      RandomForestEntr    0.851308  ...       True         6\n",
       "9        ExtraTreesEntr    0.847418  ...       True         9\n",
       "10       ExtraTreesGini    0.846548  ...       True         8\n",
       "11       NeuralNetTorch    0.838665  ...       True        12\n",
       "12       KNeighborsUnif    0.825050  ...       True         1\n",
       "13       KNeighborsDist    0.821569  ...       True         2\n",
       "\n",
       "[14 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== feature_importance ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.042542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.03912</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.030568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.02088</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.015237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.01536</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>0.012428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.01460</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>0.008520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.01260</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018102</td>\n",
       "      <td>0.007098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.00576</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.00384</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.00160</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>-0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.166374</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>-0.002928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.535135</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>-0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>-0.00012</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>-0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>-0.00016</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.722871</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>-0.001303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev   p_value  n  p99_high   p99_low\n",
       "capital-gain       0.05300  0.005079  0.000010  5  0.063458  0.042542\n",
       "marital-status     0.03912  0.004154  0.000015  5  0.047672  0.030568\n",
       "education-num      0.02088  0.002741  0.000035  5  0.026523  0.015237\n",
       "occupation         0.01536  0.001424  0.000009  5  0.018292  0.012428\n",
       "capital-loss       0.01460  0.002953  0.000190  5  0.020680  0.008520\n",
       "age                0.01260  0.002672  0.000229  5  0.018102  0.007098\n",
       "hours-per-week     0.00576  0.002406  0.002936  5  0.010714  0.000806\n",
       "workclass          0.00384  0.000767  0.000181  5  0.005419  0.002261\n",
       "sex                0.00160  0.001175  0.019097  5  0.004019 -0.000819\n",
       "relationship       0.00092  0.001869  0.166374  5  0.004768 -0.002928\n",
       "native-country    -0.00004  0.000953  0.535135  5  0.001922 -0.002002\n",
       "race              -0.00012  0.000672  0.644900  5  0.001264 -0.001504\n",
       "education         -0.00016  0.000555  0.722871  5  0.000983 -0.001303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_name ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.core.models.ensemble.weighted_ensemble_model.WeightedEnsembleModel at 0x7f5cca252980>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_params ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'max_base_models': 25,\n",
       " 'max_base_models_per_type': 5,\n",
       " 'save_bag_folds': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 20, 'result_df', '=' * 20)\n",
    "display(result_df)\n",
    "print()\n",
    "print('=' * 20, 'leader_board', '=' * 20)\n",
    "display(leader_board)\n",
    "print()\n",
    "print('=' * 20, 'feature_importance', '=' * 20)\n",
    "display(feature_importance)\n",
    "print()\n",
    "print('=' * 20, 'best_model_name', '=' * 20)\n",
    "display(best_model_name)\n",
    "print()\n",
    "print('=' * 20, 'best_model', '=' * 20)\n",
    "display(best_model)\n",
    "print()\n",
    "print('=' * 20, 'best_model_params', '=' * 20)\n",
    "display(best_model_params)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd86baa",
   "metadata": {},
   "source": [
    "# 함수화하고 분석 간단히 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f788d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automl(data, target, time = 300, metric = None) :\n",
    "    if metric in ('accuracy', 'roc_auc', 'recall', 'precision', 'f1') :\n",
    "        train_data, test_data = train_test_split(data, stratify = data[target], test_size = 0.4, random_state = 7)\n",
    "    else :\n",
    "        train_data, test_data = train_test_split(data, test_size = 0.4, random_state = 7)\n",
    "    \n",
    "    target_column = target\n",
    "    time_limit = time\n",
    "    \n",
    "    model = TabularPredictor(label = target_column, eval_metric = metric)\n",
    "    model.fit(train_data, time_limit = time_limit, presets = ['medium_quality'])\n",
    "    \n",
    "    pred = model.predict(test_data)\n",
    "    result = model.evaluate(test_data)\n",
    "    result_df = pd.DataFrame([result], index = [0])\n",
    "    \n",
    "\n",
    "    leader_board = model.leaderboard(test_data)\n",
    "\n",
    "    feature_importance = model.feature_importance(test_data)\n",
    "    \n",
    "    best_model_name = model.model_best\n",
    "\n",
    "    best_model = model._trainer.load_model(best_model_name)\n",
    "\n",
    "    best_model_params = best_model.params\n",
    "    \n",
    "    print('=' * 20, 'result_df', '=' * 20)\n",
    "    display(result_df)\n",
    "    print()\n",
    "    print('=' * 20, 'leader_board', '=' * 20)\n",
    "    display(leader_board)\n",
    "    print()\n",
    "    print('=' * 20, 'feature_importance', '=' * 20)\n",
    "    display(feature_importance)\n",
    "    print()\n",
    "    print('=' * 20, 'best_model_name', '=' * 20)\n",
    "    display(best_model_name)\n",
    "    print()\n",
    "    print('=' * 20, 'best_model', '=' * 20)\n",
    "    display(best_model)\n",
    "    print()\n",
    "    print('=' * 20, 'best_model_params', '=' * 20)\n",
    "    display(best_model_params)\n",
    "    print()\n",
    "    return best_model_name, best_model, result_df, leader_board, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58efbb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/Taitanic_train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f48ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_033735\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          12\n",
      "Memory Avail:       12.78 GB / 15.32 GB (83.4%)\n",
      "Disk Space Avail:   93.94 GB / 237.85 GB (39.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_033735\"\n",
      "Train Data Rows:    534\n",
      "Train Data Columns: 11\n",
      "Label Column:       Survived\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13082.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 8 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 5 | ['__nlp__.miss', '__nlp__.mr', '__nlp__.mrs', '__nlp__.william', '__nlp__._total_']\n",
      "\t0.3s = Fit runtime\n",
      "\t11 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 427, Val Rows: 107\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.7s of the 299.7s of remaining time.\n",
      "\t0.5701\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 299.65s of the 299.65s of remaining time.\n",
      "\t0.5607\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.62s of the 299.62s of remaining time.\n",
      "\t0.8505\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 299.17s of the 299.17s of remaining time.\n",
      "\t0.8598\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 298.73s of the 298.73s of remaining time.\n",
      "\t0.8318\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 297.89s of the 297.89s of remaining time.\n",
      "\t0.8411\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 297.04s of the 297.04s of remaining time.\n",
      "\t0.8505\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 296.18s of the 296.18s of remaining time.\n",
      "\t0.8037\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 295.42s of the 295.41s of remaining time.\n",
      "\t0.8037\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 294.61s of the 294.61s of remaining time.\n",
      "No improvement since epoch 7: early stopping\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t0.8505\t = Validation score   (accuracy)\n",
      "\t10.87s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 283.63s of the 283.63s of remaining time.\n",
      "\t0.8598\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 283.41s of the 283.41s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t0.8037\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 282.28s of the 282.28s of remaining time.\n",
      "\t0.8411\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.7s of the 281.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.5, 'XGBoost': 0.5}\n",
      "\t0.8692\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 12927.5 rows/s (107 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_033735\")\n",
      "Computing feature importance via permutation shuffling for 11 features using 357 rows with 5 shuffle sets...\n",
      "\t3.19s\t= Expected runtime (0.64s per shuffle set)\n",
      "\t0.6s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result_df ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787115</td>\n",
       "      <td>0.764966</td>\n",
       "      <td>0.555635</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.639456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy       mcc  ...        f1  precision    recall\n",
       "0  0.787115           0.764966  0.555635  ...  0.712121   0.803419  0.639456\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== leader_board ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.410363</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.410363</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.410979</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.410979</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.032810</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.182980</td>\n",
       "      <td>0.032810</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.182980</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.787115</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.044133</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.679038</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.085695</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.781513</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.831892</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.831892</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.781513</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.138137</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.731441</td>\n",
       "      <td>0.138137</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.731441</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.775910</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.137138</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.746582</td>\n",
       "      <td>0.137138</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.746582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>10.869005</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>10.869005</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.770308</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.150839</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.631722</td>\n",
       "      <td>0.150839</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.631722</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.767507</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>1.081756</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>1.081756</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.151760</td>\n",
       "      <td>0.061467</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.151760</td>\n",
       "      <td>0.061467</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  ...  can_infer fit_order\n",
       "0              LightGBM    0.803922  ...       True         4\n",
       "1            LightGBMXT    0.789916  ...       True         3\n",
       "2               XGBoost    0.789916  ...       True        11\n",
       "3   WeightedEnsemble_L2    0.787115  ...       True        14\n",
       "4              CatBoost    0.781513  ...       True         7\n",
       "5      RandomForestGini    0.781513  ...       True         5\n",
       "6      RandomForestEntr    0.775910  ...       True         6\n",
       "7       NeuralNetFastAI    0.773109  ...       True        10\n",
       "8        ExtraTreesGini    0.770308  ...       True         8\n",
       "9        NeuralNetTorch    0.767507  ...       True        12\n",
       "10        LightGBMLarge    0.764706  ...       True        13\n",
       "11       ExtraTreesEntr    0.764706  ...       True         9\n",
       "12       KNeighborsUnif    0.658263  ...       True         1\n",
       "13       KNeighborsDist    0.655462  ...       True         2\n",
       "\n",
       "[14 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== feature_importance ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.126611</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5</td>\n",
       "      <td>0.144574</td>\n",
       "      <td>0.108648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.107003</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127148</td>\n",
       "      <td>0.086858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029434</td>\n",
       "      <td>-0.004784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.138120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036507</td>\n",
       "      <td>-0.020821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>5</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>-0.012921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>-0.002585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.088904</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>-0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>-0.010790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>-0.001120</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.655771</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>-0.013080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.003361</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.983661</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>-0.008187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             importance    stddev   p_value  n  p99_high   p99_low\n",
       "Sex            0.126611  0.008724  0.000003  5  0.144574  0.108648\n",
       "Pclass         0.107003  0.009784  0.000008  5  0.127148  0.086858\n",
       "Age            0.012325  0.008309  0.014736  5  0.029434 -0.004784\n",
       "Name           0.007843  0.013921  0.138120  5  0.036507 -0.020821\n",
       "SibSp          0.005042  0.002344  0.004290  5  0.009867  0.000217\n",
       "Fare           0.005042  0.008724  0.132924  5  0.023005 -0.012921\n",
       "Embarked       0.002241  0.002344  0.049650  5  0.007066 -0.002585\n",
       "Ticket         0.001120  0.001534  0.088904  5  0.004279 -0.002039\n",
       "PassengerId    0.000000  0.005240  0.500000  5  0.010790 -0.010790\n",
       "Cabin         -0.001120  0.005809  0.655771  5  0.010839 -0.013080\n",
       "Parch         -0.003361  0.002344  0.983661  5  0.001464 -0.008187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_name ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.core.models.ensemble.weighted_ensemble_model.WeightedEnsembleModel at 0x7f5cca1bc2e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_params ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'max_base_models': 25,\n",
       " 'max_base_models_per_type': 5,\n",
       " 'save_bag_folds': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('WeightedEnsemble_L2',\n",
       " <autogluon.core.models.ensemble.weighted_ensemble_model.WeightedEnsembleModel at 0x7f5cca1bc2e0>,\n",
       "    accuracy  balanced_accuracy       mcc  ...        f1  precision    recall\n",
       " 0  0.787115           0.764966  0.555635  ...  0.712121   0.803419  0.639456\n",
       " \n",
       " [1 rows x 7 columns],\n",
       "                   model  score_test  ...  can_infer fit_order\n",
       " 0              LightGBM    0.803922  ...       True         4\n",
       " 1            LightGBMXT    0.789916  ...       True         3\n",
       " 2               XGBoost    0.789916  ...       True        11\n",
       " 3   WeightedEnsemble_L2    0.787115  ...       True        14\n",
       " 4              CatBoost    0.781513  ...       True         7\n",
       " 5      RandomForestGini    0.781513  ...       True         5\n",
       " 6      RandomForestEntr    0.775910  ...       True         6\n",
       " 7       NeuralNetFastAI    0.773109  ...       True        10\n",
       " 8        ExtraTreesGini    0.770308  ...       True         8\n",
       " 9        NeuralNetTorch    0.767507  ...       True        12\n",
       " 10        LightGBMLarge    0.764706  ...       True        13\n",
       " 11       ExtraTreesEntr    0.764706  ...       True         9\n",
       " 12       KNeighborsUnif    0.658263  ...       True         1\n",
       " 13       KNeighborsDist    0.655462  ...       True         2\n",
       " \n",
       " [14 rows x 13 columns],\n",
       "              importance    stddev   p_value  n  p99_high   p99_low\n",
       " Sex            0.126611  0.008724  0.000003  5  0.144574  0.108648\n",
       " Pclass         0.107003  0.009784  0.000008  5  0.127148  0.086858\n",
       " Age            0.012325  0.008309  0.014736  5  0.029434 -0.004784\n",
       " Name           0.007843  0.013921  0.138120  5  0.036507 -0.020821\n",
       " SibSp          0.005042  0.002344  0.004290  5  0.009867  0.000217\n",
       " Fare           0.005042  0.008724  0.132924  5  0.023005 -0.012921\n",
       " Embarked       0.002241  0.002344  0.049650  5  0.007066 -0.002585\n",
       " Ticket         0.001120  0.001534  0.088904  5  0.004279 -0.002039\n",
       " PassengerId    0.000000  0.005240  0.500000  5  0.010790 -0.010790\n",
       " Cabin         -0.001120  0.005809  0.655771  5  0.010839 -0.013080\n",
       " Parch         -0.003361  0.002344  0.983661  5  0.001464 -0.008187)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl(data, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2b07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
